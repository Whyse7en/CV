{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab6e1f67-1348-4858-8e61-58fb39f87a8a",
   "metadata": {},
   "source": [
    "Our goal in this notebook is to leverage the k-NN classifier to attempt to recognize each of cat/dog/panda species in an image using only the raw pixel intensities (i.e., no feature extraction is taking place). As we’ll see, raw pixel intensities do not lend themselves well to the k-NN algorithm. Nonetheless, this is an important benchmark experiment to run so we can appreciate why Convolutional Neural Networks are able to obtain such high accuracy on raw pixel intensities while traditional machine learning algorithms fail to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbed5eda-5775-4b8e-8243-cac41e97e2c7",
   "metadata": {},
   "source": [
    "**A basic Image Preprocessor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18676e3-dc63-4abf-868f-501ee41b35b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c226203-72d9-4d68-b3fa-202189984dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-06-03 11:10:06--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/first-image-classifier/first-image-classifier.zip\n",
      "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.92.165.26, 52.92.196.178, 52.92.213.2, ...\n",
      "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.92.165.26|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 196971354 (188M) [application/zip]\n",
      "Saving to: ‘first-image-classifier.zip’\n",
      "\n",
      "first-image-classif 100%[===================>] 187.85M   954KB/s    in 3m 11s  \n",
      "\n",
      "2023-06-03 11:13:19 (1006 KB/s) - ‘first-image-classifier.zip’ saved [196971354/196971354]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/first-image-classifier/first-image-classifier.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c29700-cb2c-462f-9665-da5b3dbdd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -qq first-image-classifier.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d8a7e7-e824-42b2-ba33-db8ba67a4d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePreprocessor:\n",
    "    \n",
    "    def __init__(self,width,hieght,inter=cv.INTER_AREA):\n",
    "        # store the target image width, height, and interpolation method used when resizing\n",
    "        self.width = width\n",
    "        self.hieght = hieght\n",
    "        self.inter = inter\n",
    "        \n",
    "    def preprocess(self,image):\n",
    "        # resize the image to a fixed size, ignoring the aspect ratio\n",
    "        return cv.resize(image,(self.width,self.hieght),interpolation=self.inter)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33de0096-cdcf-4de1-ace0-160d10ef70d4",
   "metadata": {},
   "source": [
    "**Building an Image Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "20652583-eda0-4a9a-abea-8b1eab63cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDatasetLoader:\n",
    "    def __init__(self,preprocessors=None):\n",
    "        # store the image preprocessor\n",
    "        self.preprocessors = preprocessors\n",
    "        # if the preprocessors are None, initialize them as an empty list\n",
    "        if self.preprocessors is None:\n",
    "            self.preprocessors = []\n",
    "    def load(self,imagePaths,verbose = -1):\n",
    "        \n",
    "        data = []\n",
    "        labels = []\n",
    "        \n",
    "        for (i,imagePath) in enumerate (imagePaths):\n",
    "            # load the image and extract the class label assuming\n",
    "            # that our path has the following format:\n",
    "            # /path/to/dataset/{class}/{image}.jpg\n",
    "            image = cv.imread(imagePath)\n",
    "            label = imagePath.split(os.path.sep)[-2]\n",
    "            \n",
    "            if self.preprocessors is not None:\n",
    "            # loop over the preprocessors and apply each to\n",
    "            # the image\n",
    "                for p in self.preprocessors:\n",
    "                    image = p.preprocess(image)\n",
    "            \n",
    "            # treat our processed image as a \"feature vector\"\n",
    "            # by updating the data list followed by the labels\n",
    "            data.append(image)\n",
    "            labels.append(label)\n",
    "            \n",
    "            \n",
    "            if verbose > 0 and i > 0 and (i+1) % verbose ==0:\n",
    "                # show an update every `verbose` images\n",
    "                print(\"[INFO] processed {}/{}\".format(i + 1,len(imagePaths)))\n",
    "                \n",
    "        # return a tuple of the data and labels\n",
    "        return (np.array(data), np.array(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8ab25-68c4-4916-a71d-e1e699503b56",
   "metadata": {},
   "source": [
    "As you can see, our dataset loader is simple by design; however, it affords us the ability to apply any number of image preprocessors to every image in our dataset with ease. The only caveat of this dataset loader is that it assumes that all images in the dataset can fit into main memory at once.\n",
    "\n",
    "For datasets that are too large to fit into your system’s RAM, we’ll need to design a more complex dataset loader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a4154-3f69-43c5-9ef4-1e94702ed915",
   "metadata": {},
   "source": [
    "**k-NN: A Simple Classifier**\n",
    "\n",
    "The k-Nearest Neighbor classifier is by far the most simple machine learning and image classification algorithm. In fact, it’s so simple that it doesn’t actually “learn” anything. Instead, this algorithm directly relies on the distance between feature vectors (which in our case, are the raw RGB pixel intensities of the images).\n",
    "\n",
    "Simply put, the k-NN algorithm classifies unknown data points by finding the most common class among the k closest examples. Each data point in the k closest data points casts a vote, and the category with the highest number of votes wins.\n",
    "\n",
    "**Remark**: In the event of a tie, the k-NN algorithm chooses one of the tied class labels at random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b1e68-2649-46dd-b24f-607cde5261c9",
   "metadata": {},
   "source": [
    "**k-NN Hyperparameters**\n",
    "\n",
    "There are two clear hyperparameters that we are concerned with when running the k-NN algorithm. The first is obvious: the value of k. What is the optimal value of k? If it’s too small (e.g., k = 1), then we gain efficiency but become susceptible to noise and outlier data points. However, if k is too large, then we are at risk of over-smoothing our classification results and increasing bias.\n",
    "The second parameter we should consider is the actual distance metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd6368da-47e2-4c76-8ba2-277e09410a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c006f04-5bb1-4f4c-9eb8-46837800d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"dataset\": \"./first-image-classifier/dataset/animals/\",\n",
    "    \"neighbors\": 3,\n",
    "    \"jobs\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e16d513d-12bd-4b8c-85eb-b087a3c7cd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/3000\n",
      "[INFO] processed 1000/3000\n",
      "[INFO] processed 1500/3000\n",
      "[INFO] processed 2000/3000\n",
      "[INFO] processed 2500/3000\n",
      "[INFO] processed 3000/3000\n",
      "[INFO] features matrix: 8.8MB\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args['dataset']))\n",
    "\n",
    "sp = SimplePreprocessor(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, labels) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(\n",
    "    data.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b49bfb71-0c50-4644-a139-99f0e169eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels as integers\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,\n",
    "    test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ce985fb2-fac3-466b-b4ed-b39ae418ee73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating k-NN classifier...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        cats       0.39      0.62      0.48       239\n",
      "        dogs       0.42      0.47      0.44       262\n",
      "       panda       0.92      0.29      0.44       249\n",
      "\n",
      "    accuracy                           0.46       750\n",
      "   macro avg       0.58      0.46      0.45       750\n",
      "weighted avg       0.58      0.46      0.45       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and evaluate a k-NN classifier on the raw pixel intensities\n",
    "print(\"[INFO] evaluating k-NN classifier...\")\n",
    "model = KNeighborsClassifier(n_neighbors=args[\"neighbors\"],\n",
    "    n_jobs=args[\"jobs\"])\n",
    "model.fit(trainX, trainY)\n",
    "print(classification_report(testY, model.predict(testX),\n",
    "    target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758fd326-684d-44ac-8d15-8105ce69b7cd",
   "metadata": {},
   "source": [
    "**Pros and Cons of k-NN**\n",
    "\n",
    "One main advantage of the k-NN algorithm is that it’s extremely simple to implement and understand. Furthermore, the classifier takes absolutely no time to train, since all we need to do is store our data points for the purpose of later computing distances to them and obtaining our final classification.\n",
    "\n",
    "However, we pay for this simplicity at classification time. Classifying a new testing point requires a comparison to every single data point in our training data, which scales O(N), making working with larger datasets computationally prohibitive.\n",
    "\n",
    "Finally, the k-NN algorithm is more suited for low-dimensional feature spaces (which images are not). Distances in high-dimensional feature spaces are often unintuitive.\n",
    "\n",
    "It’s also important to note that the k-NN algorithm doesn’t actually “learn” anything — the algorithm is not able to make itself smarter if it makes mistakes; it’s simply relying on distances in an n-dimensional space to make the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ed62ae-6232-4da4-86a0-6d3f1fd4b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
